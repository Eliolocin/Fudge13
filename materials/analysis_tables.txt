% Performance Metrics Comparison Table
\begin{table}[htbp]
\caption{Performance Metrics Comparison: Prompt-engineered vs Agentic LLM Judge}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Metric} & \textbf{Prompt-engineered} & \textbf{Agentic} \\
\hline
Accuracy & 0.783 & 0.525 \\
\hline
Precision & 0.836 & 0.673 \\
\hline
Recall & 0.813 & 0.467 \\
\hline
F1-Score & 0.824 & 0.551 \\
\hline
\end{tabular}
\label{tab:performance_metrics}
\end{center}
\end{table}

% Descriptive Statistics Table
\begin{table}[htbp]
\caption{Descriptive Statistics: LLM vs Human Score Comparison}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Scorer} & \textbf{Mean} & \textbf{Std} & \textbf{Range} \\
\hline
\multirow{2}{*}{\textbf{Prompt-engineered}} & LLM & 3.61 & 1.42 & 1-5 \\
\cline{2-5}
 & Human & 3.38 & 1.55 & 1-5 \\
\hline
\multirow{2}{*}{\textbf{Agentic}} & LLM & 2.77 & 1.64 & 1-5 \\
\cline{2-5}
 & Human & 3.38 & 1.55 & 1-5 \\
\hline
\end{tabular}
\label{tab:descriptive_stats}
\end{center}
\end{table}

% Consistency Analysis Table
\begin{table}[htbp]
\caption{Consistency Analysis and Correlation with Human Judgments}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Pass} & \textbf{Score} & \textbf{Correlation} & \textbf{p-value} \\
 & \textbf{Consistency} & \textbf{Std} & \textbf{(r)} & \\
\hline
Prompt-engineered & 0.933 & 0.628 & 0.067 & 1.874 \\
\hline
Agentic & 0.833 & 0.922 & -0.049 & 0.593 \\
\hline
\end{tabular}
\label{tab:consistency}
\end{center}
\end{table}
